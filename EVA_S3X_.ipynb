{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA S3X .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d4adb0cc2a44cccaf3e1102f07b7556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b8aa86aa4294271a2dbf597fd07874c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dba84e09cd9f4e918929ee3ad48234d1",
              "IPY_MODEL_5a61c67c03514222adc6db2ced1dbce4"
            ]
          }
        },
        "8b8aa86aa4294271a2dbf597fd07874c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dba84e09cd9f4e918929ee3ad48234d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b126a01652364ad3848ae28e0c76d3ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43bf4d5c92a9473087a89d898d761b4c"
          }
        },
        "5a61c67c03514222adc6db2ced1dbce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_242c5c6e591f4220bcc37a456fafef73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 561758208/? [00:20&lt;00:00, 77798602.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96f059d5798b474c85d847e16530857c"
          }
        },
        "b126a01652364ad3848ae28e0c76d3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43bf4d5c92a9473087a89d898d761b4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "242c5c6e591f4220bcc37a456fafef73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96f059d5798b474c85d847e16530857c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hameeda1512/EVA-Assignments/blob/main/EVA_S3X_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtKvmZx-WmUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfbd930-bb6e-4237-d4dc-93103aa66107"
      },
      "source": [
        "# Installing Pytorch\n",
        "\n",
        "!pip install torch\n",
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGU6NwlsXFSt"
      },
      "source": [
        "#Import Dependencies\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bNfVLRUYqZA"
      },
      "source": [
        "#Define Hyperparameters\n",
        "\n",
        "num_classes = 62 # number of output classes discrete range [0,9]\n",
        "num_epochs = 20 # number of times which the entire dataset is passed throughout the model\n",
        "batch_size = 100 # the size of input data took for one iteration\n",
        "lr = 1e-3 # size of step "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCsBCXMwbpH5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "5d4adb0cc2a44cccaf3e1102f07b7556",
            "8b8aa86aa4294271a2dbf597fd07874c",
            "dba84e09cd9f4e918929ee3ad48234d1",
            "5a61c67c03514222adc6db2ced1dbce4",
            "b126a01652364ad3848ae28e0c76d3ac",
            "43bf4d5c92a9473087a89d898d761b4c",
            "242c5c6e591f4220bcc37a456fafef73",
            "96f059d5798b474c85d847e16530857c"
          ]
        },
        "outputId": "0294bc65-a9c3-423f-e5d4-7c4f158a644a"
      },
      "source": [
        "#Downloading EMNIST data\n",
        "\n",
        "train_data = dsets.EMNIST(root = './data', train = True,\n",
        "                        transform = transforms.ToTensor(),\n",
        "                        download = True,\n",
        "                        split='byclass')\n",
        "\n",
        "test_data = dsets.EMNIST(root = './data', train = False,\n",
        "                       transform = transforms.ToTensor(),\n",
        "                       split='byclass')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting zip archive\n",
            "Downloading http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data/EMNIST/raw/emnist.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d4adb0cc2a44cccaf3e1102f07b7556",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/EMNIST/raw/emnist.zip to ./data/EMNIST/raw\n",
            "Processing byclass\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing bymerge\n",
            "Processing balanced\n",
            "Processing letters\n",
            "Processing digits\n",
            "Processing mnist\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfDPBdnYgfGp"
      },
      "source": [
        "#Loading the data\n",
        "\n",
        "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL-YXTvghaz_"
      },
      "source": [
        "#Define model class\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv1= nn.Conv2d(in_channels= 1, out_channels= 10, kernel_size= 3, padding= 1)\n",
        "    self.conv2= nn.Conv2d(in_channels= 10, out_channels= 10, kernel_size= 3,padding= 1 )\n",
        "    self.max_pool1= nn.MaxPool2d(2, stride= 2) #28x28x10 > 14x14x10 ; RF: 10x10\n",
        "    self.conv3= nn.Conv2d(in_channels= 10, out_channels= 20, kernel_size= 3, padding=1 )\n",
        "    self.conv4= nn.Conv2d(in_channels= 20, out_channels= 20, kernel_size= 3, padding= 1)\n",
        "    self.max_pool2= nn.MaxPool2d(2, stride= 2)\n",
        "    self.conv5= nn.Conv2d(in_channels= 20, out_channels=30, kernel_size= 3 ) \n",
        "    self.conv6= nn.Conv2d(in_channels= 30, out_channels= 30, kernel_size= 3) \n",
        "    \n",
        "    \n",
        "    self.fc1 = nn.Linear(30*3*3, 62)\n",
        "    # self.relu = nn.ReLU()\n",
        "    # self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "  \n",
        "  def forward(self,t):\n",
        "    t= self.max_pool1(F.relu(self.conv2(F.relu(self.conv1(t)))))\n",
        "    t= self.max_pool2(F.relu(self.conv4(F.relu(self.conv3(t)))))\n",
        "    t= self.conv6(F.relu(self.conv5(t)))\n",
        "    t= t.reshape(-1, 30*3*3)\n",
        "    out = self.fc1(t)\n",
        "    # out = self.relu(out)\n",
        "    # out = self.fc2(out)\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3EPEqbjjfAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01de85bf-28df-4a51-a629-596c4acb3552"
      },
      "source": [
        "#Build the model\n",
        "# !pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "net = Net(input_size, hidden_size, num_classes)\n",
        "if torch.cuda.is_available():\n",
        "  net.cuda()\n",
        "\n",
        "summary(net, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 28, 28]             100\n",
            "            Conv2d-2           [-1, 10, 28, 28]             910\n",
            "         MaxPool2d-3           [-1, 10, 14, 14]               0\n",
            "            Conv2d-4           [-1, 20, 14, 14]           1,820\n",
            "            Conv2d-5           [-1, 20, 14, 14]           3,620\n",
            "         MaxPool2d-6             [-1, 20, 7, 7]               0\n",
            "            Conv2d-7             [-1, 30, 5, 5]           5,430\n",
            "            Conv2d-8             [-1, 30, 3, 3]           8,130\n",
            "            Linear-9                   [-1, 62]          16,802\n",
            "================================================================\n",
            "Total params: 36,812\n",
            "Trainable params: 36,812\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.21\n",
            "Params size (MB): 0.14\n",
            "Estimated Total Size (MB): 0.35\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePLIwvAFj2zH"
      },
      "source": [
        "#Define loss-function & optimizer\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam( net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u75Xa5VckuTH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cc2d11d-f136-413b-bf5a-b6266f872ad8"
      },
      "source": [
        "#Training the model\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i ,(images,labels) in enumerate(train_gen):\n",
        "    images = Variable(images).cuda()\n",
        "    labels = Variable(labels).cuda()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (i+1) % 100 == 0:\n",
        "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/6979], Loss: 3.9188\n",
            "Epoch [1/20], Step [200/6979], Loss: 3.9808\n",
            "Epoch [1/20], Step [300/6979], Loss: 3.2568\n",
            "Epoch [1/20], Step [400/6979], Loss: 2.9088\n",
            "Epoch [1/20], Step [500/6979], Loss: 2.9926\n",
            "Epoch [1/20], Step [600/6979], Loss: 2.5663\n",
            "Epoch [1/20], Step [700/6979], Loss: 2.3256\n",
            "Epoch [1/20], Step [800/6979], Loss: 2.5655\n",
            "Epoch [1/20], Step [900/6979], Loss: 1.7103\n",
            "Epoch [1/20], Step [1000/6979], Loss: 1.7852\n",
            "Epoch [1/20], Step [1100/6979], Loss: 1.8687\n",
            "Epoch [1/20], Step [1200/6979], Loss: 1.5529\n",
            "Epoch [1/20], Step [1300/6979], Loss: 1.6301\n",
            "Epoch [1/20], Step [1400/6979], Loss: 1.6053\n",
            "Epoch [1/20], Step [1500/6979], Loss: 1.2831\n",
            "Epoch [1/20], Step [1600/6979], Loss: 1.8169\n",
            "Epoch [1/20], Step [1700/6979], Loss: 1.3362\n",
            "Epoch [1/20], Step [1800/6979], Loss: 1.1770\n",
            "Epoch [1/20], Step [1900/6979], Loss: 1.3764\n",
            "Epoch [1/20], Step [2000/6979], Loss: 1.5231\n",
            "Epoch [1/20], Step [2100/6979], Loss: 1.4929\n",
            "Epoch [1/20], Step [2200/6979], Loss: 1.0528\n",
            "Epoch [1/20], Step [2300/6979], Loss: 1.3807\n",
            "Epoch [1/20], Step [2400/6979], Loss: 1.4210\n",
            "Epoch [1/20], Step [2500/6979], Loss: 1.2901\n",
            "Epoch [1/20], Step [2600/6979], Loss: 1.5826\n",
            "Epoch [1/20], Step [2700/6979], Loss: 1.4312\n",
            "Epoch [1/20], Step [2800/6979], Loss: 1.4809\n",
            "Epoch [1/20], Step [2900/6979], Loss: 1.0589\n",
            "Epoch [1/20], Step [3000/6979], Loss: 1.2438\n",
            "Epoch [1/20], Step [3100/6979], Loss: 1.1616\n",
            "Epoch [1/20], Step [3200/6979], Loss: 1.4732\n",
            "Epoch [1/20], Step [3300/6979], Loss: 1.3851\n",
            "Epoch [1/20], Step [3400/6979], Loss: 1.0461\n",
            "Epoch [1/20], Step [3500/6979], Loss: 1.3257\n",
            "Epoch [1/20], Step [3600/6979], Loss: 1.0264\n",
            "Epoch [1/20], Step [3700/6979], Loss: 1.3064\n",
            "Epoch [1/20], Step [3800/6979], Loss: 1.0784\n",
            "Epoch [1/20], Step [3900/6979], Loss: 0.8696\n",
            "Epoch [1/20], Step [4000/6979], Loss: 0.8849\n",
            "Epoch [1/20], Step [4100/6979], Loss: 1.2985\n",
            "Epoch [1/20], Step [4200/6979], Loss: 0.9920\n",
            "Epoch [1/20], Step [4300/6979], Loss: 1.0725\n",
            "Epoch [1/20], Step [4400/6979], Loss: 1.0314\n",
            "Epoch [1/20], Step [4500/6979], Loss: 1.0792\n",
            "Epoch [1/20], Step [4600/6979], Loss: 0.9900\n",
            "Epoch [1/20], Step [4700/6979], Loss: 0.9523\n",
            "Epoch [1/20], Step [4800/6979], Loss: 1.1270\n",
            "Epoch [1/20], Step [4900/6979], Loss: 0.6619\n",
            "Epoch [1/20], Step [5000/6979], Loss: 1.2007\n",
            "Epoch [1/20], Step [5100/6979], Loss: 1.1355\n",
            "Epoch [1/20], Step [5200/6979], Loss: 0.9609\n",
            "Epoch [1/20], Step [5300/6979], Loss: 1.0456\n",
            "Epoch [1/20], Step [5400/6979], Loss: 0.9149\n",
            "Epoch [1/20], Step [5500/6979], Loss: 1.1423\n",
            "Epoch [1/20], Step [5600/6979], Loss: 0.6692\n",
            "Epoch [1/20], Step [5700/6979], Loss: 0.9472\n",
            "Epoch [1/20], Step [5800/6979], Loss: 0.8706\n",
            "Epoch [1/20], Step [5900/6979], Loss: 0.7466\n",
            "Epoch [1/20], Step [6000/6979], Loss: 1.0548\n",
            "Epoch [1/20], Step [6100/6979], Loss: 0.9648\n",
            "Epoch [1/20], Step [6200/6979], Loss: 0.9564\n",
            "Epoch [1/20], Step [6300/6979], Loss: 1.0055\n",
            "Epoch [1/20], Step [6400/6979], Loss: 1.0554\n",
            "Epoch [1/20], Step [6500/6979], Loss: 0.6656\n",
            "Epoch [1/20], Step [6600/6979], Loss: 1.0548\n",
            "Epoch [1/20], Step [6700/6979], Loss: 0.6628\n",
            "Epoch [1/20], Step [6800/6979], Loss: 1.0279\n",
            "Epoch [1/20], Step [6900/6979], Loss: 0.8607\n",
            "Epoch [2/20], Step [100/6979], Loss: 0.8817\n",
            "Epoch [2/20], Step [200/6979], Loss: 1.2156\n",
            "Epoch [2/20], Step [300/6979], Loss: 0.8894\n",
            "Epoch [2/20], Step [400/6979], Loss: 1.2145\n",
            "Epoch [2/20], Step [500/6979], Loss: 0.8864\n",
            "Epoch [2/20], Step [600/6979], Loss: 0.9170\n",
            "Epoch [2/20], Step [700/6979], Loss: 0.8990\n",
            "Epoch [2/20], Step [800/6979], Loss: 1.0840\n",
            "Epoch [2/20], Step [900/6979], Loss: 0.7006\n",
            "Epoch [2/20], Step [1000/6979], Loss: 0.8086\n",
            "Epoch [2/20], Step [1100/6979], Loss: 0.8004\n",
            "Epoch [2/20], Step [1200/6979], Loss: 1.0417\n",
            "Epoch [2/20], Step [1300/6979], Loss: 0.7782\n",
            "Epoch [2/20], Step [1400/6979], Loss: 0.7200\n",
            "Epoch [2/20], Step [1500/6979], Loss: 1.0316\n",
            "Epoch [2/20], Step [1600/6979], Loss: 0.9016\n",
            "Epoch [2/20], Step [1700/6979], Loss: 0.7153\n",
            "Epoch [2/20], Step [1800/6979], Loss: 0.8328\n",
            "Epoch [2/20], Step [1900/6979], Loss: 0.9257\n",
            "Epoch [2/20], Step [2000/6979], Loss: 0.7730\n",
            "Epoch [2/20], Step [2100/6979], Loss: 0.8208\n",
            "Epoch [2/20], Step [2200/6979], Loss: 1.0613\n",
            "Epoch [2/20], Step [2300/6979], Loss: 0.8473\n",
            "Epoch [2/20], Step [2400/6979], Loss: 0.8916\n",
            "Epoch [2/20], Step [2500/6979], Loss: 0.9628\n",
            "Epoch [2/20], Step [2600/6979], Loss: 0.7771\n",
            "Epoch [2/20], Step [2700/6979], Loss: 0.9653\n",
            "Epoch [2/20], Step [2800/6979], Loss: 0.7544\n",
            "Epoch [2/20], Step [2900/6979], Loss: 0.8457\n",
            "Epoch [2/20], Step [3000/6979], Loss: 0.9474\n",
            "Epoch [2/20], Step [3100/6979], Loss: 0.7979\n",
            "Epoch [2/20], Step [3200/6979], Loss: 0.8359\n",
            "Epoch [2/20], Step [3300/6979], Loss: 0.9232\n",
            "Epoch [2/20], Step [3400/6979], Loss: 0.9695\n",
            "Epoch [2/20], Step [3500/6979], Loss: 0.8706\n",
            "Epoch [2/20], Step [3600/6979], Loss: 0.5252\n",
            "Epoch [2/20], Step [3700/6979], Loss: 0.6983\n",
            "Epoch [2/20], Step [3800/6979], Loss: 0.8986\n",
            "Epoch [2/20], Step [3900/6979], Loss: 0.7316\n",
            "Epoch [2/20], Step [4000/6979], Loss: 0.7542\n",
            "Epoch [2/20], Step [4100/6979], Loss: 0.8567\n",
            "Epoch [2/20], Step [4200/6979], Loss: 0.6460\n",
            "Epoch [2/20], Step [4300/6979], Loss: 1.0068\n",
            "Epoch [2/20], Step [4400/6979], Loss: 0.6397\n",
            "Epoch [2/20], Step [4500/6979], Loss: 0.8858\n",
            "Epoch [2/20], Step [4600/6979], Loss: 0.9181\n",
            "Epoch [2/20], Step [4700/6979], Loss: 1.0525\n",
            "Epoch [2/20], Step [4800/6979], Loss: 0.9604\n",
            "Epoch [2/20], Step [4900/6979], Loss: 0.5956\n",
            "Epoch [2/20], Step [5000/6979], Loss: 0.8801\n",
            "Epoch [2/20], Step [5100/6979], Loss: 0.9321\n",
            "Epoch [2/20], Step [5200/6979], Loss: 0.7039\n",
            "Epoch [2/20], Step [5300/6979], Loss: 1.2084\n",
            "Epoch [2/20], Step [5400/6979], Loss: 1.0190\n",
            "Epoch [2/20], Step [5500/6979], Loss: 0.8589\n",
            "Epoch [2/20], Step [5600/6979], Loss: 0.7432\n",
            "Epoch [2/20], Step [5700/6979], Loss: 0.7873\n",
            "Epoch [2/20], Step [5800/6979], Loss: 0.9037\n",
            "Epoch [2/20], Step [5900/6979], Loss: 0.5655\n",
            "Epoch [2/20], Step [6000/6979], Loss: 0.7494\n",
            "Epoch [2/20], Step [6100/6979], Loss: 0.6084\n",
            "Epoch [2/20], Step [6200/6979], Loss: 0.7269\n",
            "Epoch [2/20], Step [6300/6979], Loss: 0.7608\n",
            "Epoch [2/20], Step [6400/6979], Loss: 0.7026\n",
            "Epoch [2/20], Step [6500/6979], Loss: 0.7442\n",
            "Epoch [2/20], Step [6600/6979], Loss: 0.6974\n",
            "Epoch [2/20], Step [6700/6979], Loss: 0.7479\n",
            "Epoch [2/20], Step [6800/6979], Loss: 0.7049\n",
            "Epoch [2/20], Step [6900/6979], Loss: 0.7031\n",
            "Epoch [3/20], Step [100/6979], Loss: 0.7237\n",
            "Epoch [3/20], Step [200/6979], Loss: 0.7398\n",
            "Epoch [3/20], Step [300/6979], Loss: 0.7563\n",
            "Epoch [3/20], Step [400/6979], Loss: 0.7346\n",
            "Epoch [3/20], Step [500/6979], Loss: 0.9843\n",
            "Epoch [3/20], Step [600/6979], Loss: 0.8446\n",
            "Epoch [3/20], Step [700/6979], Loss: 0.5924\n",
            "Epoch [3/20], Step [800/6979], Loss: 0.9522\n",
            "Epoch [3/20], Step [900/6979], Loss: 1.0271\n",
            "Epoch [3/20], Step [1000/6979], Loss: 0.5756\n",
            "Epoch [3/20], Step [1100/6979], Loss: 0.9860\n",
            "Epoch [3/20], Step [1200/6979], Loss: 0.7123\n",
            "Epoch [3/20], Step [1300/6979], Loss: 0.7779\n",
            "Epoch [3/20], Step [1400/6979], Loss: 0.7997\n",
            "Epoch [3/20], Step [1500/6979], Loss: 0.8688\n",
            "Epoch [3/20], Step [1600/6979], Loss: 0.7041\n",
            "Epoch [3/20], Step [1700/6979], Loss: 0.6298\n",
            "Epoch [3/20], Step [1800/6979], Loss: 0.5551\n",
            "Epoch [3/20], Step [1900/6979], Loss: 0.7671\n",
            "Epoch [3/20], Step [2000/6979], Loss: 0.7484\n",
            "Epoch [3/20], Step [2100/6979], Loss: 0.6245\n",
            "Epoch [3/20], Step [2200/6979], Loss: 0.8747\n",
            "Epoch [3/20], Step [2300/6979], Loss: 0.7357\n",
            "Epoch [3/20], Step [2400/6979], Loss: 0.6899\n",
            "Epoch [3/20], Step [2500/6979], Loss: 0.9466\n",
            "Epoch [3/20], Step [2600/6979], Loss: 0.7446\n",
            "Epoch [3/20], Step [2700/6979], Loss: 0.7991\n",
            "Epoch [3/20], Step [2800/6979], Loss: 0.7027\n",
            "Epoch [3/20], Step [2900/6979], Loss: 0.8925\n",
            "Epoch [3/20], Step [3000/6979], Loss: 0.5934\n",
            "Epoch [3/20], Step [3100/6979], Loss: 0.7449\n",
            "Epoch [3/20], Step [3200/6979], Loss: 0.7058\n",
            "Epoch [3/20], Step [3300/6979], Loss: 0.7671\n",
            "Epoch [3/20], Step [3400/6979], Loss: 0.5738\n",
            "Epoch [3/20], Step [3500/6979], Loss: 0.6219\n",
            "Epoch [3/20], Step [3600/6979], Loss: 0.7218\n",
            "Epoch [3/20], Step [3700/6979], Loss: 0.6494\n",
            "Epoch [3/20], Step [3800/6979], Loss: 0.6980\n",
            "Epoch [3/20], Step [3900/6979], Loss: 0.8565\n",
            "Epoch [3/20], Step [4000/6979], Loss: 0.7290\n",
            "Epoch [3/20], Step [4100/6979], Loss: 0.7278\n",
            "Epoch [3/20], Step [4200/6979], Loss: 0.8177\n",
            "Epoch [3/20], Step [4300/6979], Loss: 0.6079\n",
            "Epoch [3/20], Step [4400/6979], Loss: 0.6014\n",
            "Epoch [3/20], Step [4500/6979], Loss: 0.6187\n",
            "Epoch [3/20], Step [4600/6979], Loss: 0.5468\n",
            "Epoch [3/20], Step [4700/6979], Loss: 0.7120\n",
            "Epoch [3/20], Step [4800/6979], Loss: 0.6612\n",
            "Epoch [3/20], Step [4900/6979], Loss: 0.7697\n",
            "Epoch [3/20], Step [5000/6979], Loss: 0.6397\n",
            "Epoch [3/20], Step [5100/6979], Loss: 0.5435\n",
            "Epoch [3/20], Step [5200/6979], Loss: 0.8982\n",
            "Epoch [3/20], Step [5300/6979], Loss: 0.6082\n",
            "Epoch [3/20], Step [5400/6979], Loss: 0.6002\n",
            "Epoch [3/20], Step [5500/6979], Loss: 0.4370\n",
            "Epoch [3/20], Step [5600/6979], Loss: 0.7168\n",
            "Epoch [3/20], Step [5700/6979], Loss: 0.5333\n",
            "Epoch [3/20], Step [5800/6979], Loss: 0.7247\n",
            "Epoch [3/20], Step [5900/6979], Loss: 0.7232\n",
            "Epoch [3/20], Step [6000/6979], Loss: 0.6298\n",
            "Epoch [3/20], Step [6100/6979], Loss: 1.0245\n",
            "Epoch [3/20], Step [6200/6979], Loss: 0.8479\n",
            "Epoch [3/20], Step [6300/6979], Loss: 0.7071\n",
            "Epoch [3/20], Step [6400/6979], Loss: 0.5952\n",
            "Epoch [3/20], Step [6500/6979], Loss: 0.6176\n",
            "Epoch [3/20], Step [6600/6979], Loss: 0.5854\n",
            "Epoch [3/20], Step [6700/6979], Loss: 0.5446\n",
            "Epoch [3/20], Step [6800/6979], Loss: 0.6482\n",
            "Epoch [3/20], Step [6900/6979], Loss: 0.7083\n",
            "Epoch [4/20], Step [100/6979], Loss: 0.6354\n",
            "Epoch [4/20], Step [200/6979], Loss: 0.5554\n",
            "Epoch [4/20], Step [300/6979], Loss: 1.0259\n",
            "Epoch [4/20], Step [400/6979], Loss: 0.6849\n",
            "Epoch [4/20], Step [500/6979], Loss: 0.5851\n",
            "Epoch [4/20], Step [600/6979], Loss: 0.7948\n",
            "Epoch [4/20], Step [700/6979], Loss: 0.8218\n",
            "Epoch [4/20], Step [800/6979], Loss: 0.5279\n",
            "Epoch [4/20], Step [900/6979], Loss: 0.7388\n",
            "Epoch [4/20], Step [1000/6979], Loss: 0.6772\n",
            "Epoch [4/20], Step [1100/6979], Loss: 0.6089\n",
            "Epoch [4/20], Step [1200/6979], Loss: 0.7436\n",
            "Epoch [4/20], Step [1300/6979], Loss: 0.7823\n",
            "Epoch [4/20], Step [1400/6979], Loss: 0.7349\n",
            "Epoch [4/20], Step [1500/6979], Loss: 0.6679\n",
            "Epoch [4/20], Step [1600/6979], Loss: 0.5465\n",
            "Epoch [4/20], Step [1700/6979], Loss: 0.5183\n",
            "Epoch [4/20], Step [1800/6979], Loss: 0.6176\n",
            "Epoch [4/20], Step [1900/6979], Loss: 0.6899\n",
            "Epoch [4/20], Step [2000/6979], Loss: 0.7039\n",
            "Epoch [4/20], Step [2100/6979], Loss: 0.5851\n",
            "Epoch [4/20], Step [2200/6979], Loss: 0.7163\n",
            "Epoch [4/20], Step [2300/6979], Loss: 0.6575\n",
            "Epoch [4/20], Step [2400/6979], Loss: 0.7049\n",
            "Epoch [4/20], Step [2500/6979], Loss: 0.6171\n",
            "Epoch [4/20], Step [2600/6979], Loss: 0.8534\n",
            "Epoch [4/20], Step [2700/6979], Loss: 0.6021\n",
            "Epoch [4/20], Step [2800/6979], Loss: 0.6366\n",
            "Epoch [4/20], Step [2900/6979], Loss: 0.7862\n",
            "Epoch [4/20], Step [3000/6979], Loss: 0.6001\n",
            "Epoch [4/20], Step [3100/6979], Loss: 0.5675\n",
            "Epoch [4/20], Step [3200/6979], Loss: 0.5093\n",
            "Epoch [4/20], Step [3300/6979], Loss: 0.6985\n",
            "Epoch [4/20], Step [3400/6979], Loss: 0.3636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c2b7a7a77df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mbufsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m65536\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# see RawEncode.c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTPvMW5jHB9X"
      },
      "source": [
        "#Evaluating the accuracy of the model\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "for images,labels in test_gen:\n",
        "  images = Variable(images.view(-1,28*28)).cuda()\n",
        "  labels = labels.cuda()\n",
        "  \n",
        "  output = net(images)\n",
        "  _, predicted = torch.max(output,1)\n",
        "  correct += (predicted == labels).sum()\n",
        "  total += labels.size(0)\n",
        "\n",
        "print('Accuracy of the model: %.3f %%' %((100*correct)/(total+1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}